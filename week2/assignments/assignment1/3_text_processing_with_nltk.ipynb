{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63fef12a",
   "metadata": {},
   "source": [
    "## Text Processing with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d6626c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "163c2236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\devar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\devar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\devar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\devar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\devar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary NLTK resources (only run once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1b42baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text for processing\n",
    "text = \"\"\"The enthralling 2-2 draw for the Anderson-Tendulkar trophy between England and India provided a dramatic start to the new World Test Championship cycle. It was an epic contest, each of the five Tests going into the final day, four in fact into the final session, providing some of the best individual and collective performances the five-day format has seen in recent years.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9a06808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "tokens = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9407711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words and word.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24bc98f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tagging\n",
    "pos_tags = nltk.pos_tag(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ff75bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count nouns, verbs, adjectives\n",
    "pos_counts = Counter(tag for word, tag in pos_tags)\n",
    "\n",
    "num_nouns = sum(count for tag, count in pos_counts.items() if tag.startswith('NN'))\n",
    "num_verbs = sum(count for tag, count in pos_counts.items() if tag.startswith('VB'))\n",
    "num_adjectives = sum(count for tag, count in pos_counts.items() if tag.startswith('JJ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7785843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tokens: ['The', 'enthralling', '2-2', 'draw', 'for', 'the', 'Anderson-Tendulkar', 'trophy', 'between', 'England', 'and', 'India', 'provided', 'a', 'dramatic', 'start', 'to', 'the', 'new', 'World', 'Test', 'Championship', 'cycle', '.', 'It', 'was', 'an', 'epic', 'contest', ',', 'each', 'of', 'the', 'five', 'Tests', 'going', 'into', 'the', 'final', 'day', ',', 'four', 'in', 'fact', 'into', 'the', 'final', 'session', ',', 'providing', 'some', 'of', 'the', 'best', 'individual', 'and', 'collective', 'performances', 'the', 'five-day', 'format', 'has', 'seen', 'in', 'recent', 'years', '.']\n",
      "Filtered Tokens (No Stopwords): ['enthralling', 'draw', 'trophy', 'England', 'India', 'provided', 'dramatic', 'start', 'new', 'World', 'Test', 'Championship', 'cycle', 'epic', 'contest', 'five', 'Tests', 'going', 'final', 'day', 'four', 'fact', 'final', 'session', 'providing', 'best', 'individual', 'collective', 'performances', 'format', 'seen', 'recent', 'years']\n",
      "POS Tags: [('enthralling', 'VBG'), ('draw', 'JJ'), ('trophy', 'NN'), ('England', 'NNP'), ('India', 'NNP'), ('provided', 'VBD'), ('dramatic', 'JJ'), ('start', 'RB'), ('new', 'JJ'), ('World', 'NNP'), ('Test', 'NNP'), ('Championship', 'NNP'), ('cycle', 'NN'), ('epic', 'NN'), ('contest', 'NN'), ('five', 'CD'), ('Tests', 'NNS'), ('going', 'VBG'), ('final', 'JJ'), ('day', 'NN'), ('four', 'CD'), ('fact', 'NN'), ('final', 'JJ'), ('session', 'NN'), ('providing', 'VBG'), ('best', 'JJS'), ('individual', 'JJ'), ('collective', 'NN'), ('performances', 'NNS'), ('format', 'VBP'), ('seen', 'VBN'), ('recent', 'JJ'), ('years', 'NNS')]\n",
      "Number of Nouns: 16\n",
      "Number of Verbs: 6\n",
      "Number of Adjectives: 8\n"
     ]
    }
   ],
   "source": [
    "# Output results\n",
    "print(\"Original Tokens:\", tokens)\n",
    "print(\"Filtered Tokens (No Stopwords):\", filtered_tokens)\n",
    "print(\"POS Tags:\", pos_tags)\n",
    "print(f\"Number of Nouns: {num_nouns}\")\n",
    "print(f\"Number of Verbs: {num_verbs}\")\n",
    "print(f\"Number of Adjectives: {num_adjectives}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a64c9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b322c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e415ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
